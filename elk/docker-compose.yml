version: '2'
# This compose file stands up Scrapy Cluster with an
# associated ELK Stack. You should run a few crawls and then import the
# `export.json` file into your Kibana objects

services:
  kafka_monitor:
    image: istresearch/scrapy-cluster:kafka-monitor-dev
    volumes:
      - logs:/usr/src/app/logs
    environment:
      - LOG_STDOUT=False
      - LOG_JSON=True
      - LOG_LEVEL=DEBUG
    depends_on:
      - kafka
      - redis
  redis_monitor:
    image: istresearch/scrapy-cluster:redis-monitor-dev
    volumes:
      - logs:/usr/src/app/logs
    environment:
      - LOG_STDOUT=False
      - LOG_JSON=True
      - LOG_LEVEL=DEBUG
    depends_on:
      - kafka
      - redis
      - zookeeper
  crawler:
    image: carnie/scrapy-cluster:crawler-dev
    build:
      context: ..
      dockerfile: docker/crawler/Dockerfile.py3
    volumes:
      - logs:/usr/src/app/logs
    environment:
      - SC_LOG_STDOUT=False
      - SC_LOG_JSON=True
      - LOG_LEVEL=DEBUG
    depends_on:
      - kafka
      - redis
      - zookeeper
      - mongo
  rest:
    image: istresearch/scrapy-cluster:rest-dev
    volumes:
      - logs:/usr/src/app/logs
    depends_on:
      - kafka
      - redis
    ports:
      - "5343:5343"
    environment:
      - LOG_STDOUT=False
      - LOG_JSON=True
      - LOG_LEVEL=DEBUG
  redis:
    image: redis
    ports:
      - "6379"
    # command: redis-server --requirepass redispassword
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ADVERTISED_HOST_NAME: kafka
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - zookeeper
  mongo:
    image: "mongo:bionic"
    ports:
    - "27017:27017"
  elasticsearch:
    image: elasticsearch:7.16.3
    command: elasticsearch -E network.host=0.0.0.0 -E discovery.type=single-node
    ports:
      - "9200:9200"
      - "9300:9300"
  logstash:
    image: logstash:7.16.3
    command: logstash -f /etc/logstash/conf.d/logstash.conf
    volumes:
      - ./scrapy-cluster-logstash-docker.conf:/etc/logstash/conf.d/logstash.conf
      - ./logs-template.json:/etc/logstash/templates/logs-template.json
      - logs:/var/log/scrapy-cluster
    ports:
      - "5000:5000"
    links:
      - elasticsearch
  kibana:
    image: kibana:7.16.3
    ports:
      - "5601:5601"
    links:
      - elasticsearch

volumes:
  logs:
